# prompt-rebellion
A resource for the latest adversarial prompting and llm security news and references

- Adversarial Prompting References
  - https://github.com/dair-ai/Prompt-Engineering-Guide/blob/main/guides/prompts-adversarial.md
  - https://arxiv.org/pdf/2302.04237.pdf
  - https://arxiv.org/pdf/2203.10714.pdf
  - https://arxiv.org/pdf/2302.12173v1.pdf
  - https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.100-2e2023.ipd.pdf
  - https://huggingface.co/blog/red-teaming
  - https://learnprompting.org/docs/prompt_hacking/defensive_measures
  - https://www.surgehq.ai/blog/ai-red-teams-for-adversarial-training-making-chatgpt-and-large-language-models-adversarially-robust

- LLM Application Security References
  - https://shreyar.github.io/guardrails/
  - https://www.darkreading.com/operations/threat-modeling-in-the-age-of-openai-s-chatbot
  - [When will Adam be replaced by ChatGPT?](https://youtu.be/9k3scZFKYYA)
  - [More on GPT3 and threat modeling](https://shostack.org/blog/more-on-gpt3/)
